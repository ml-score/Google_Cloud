{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "V1bmkkXRt-EM",
   "metadata": {
    "id": "V1bmkkXRt-EM"
   },
   "source": [
    "# Basic BigQuery Operations - Loading Binary Classification Data \n",
    "\n",
    "<img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "\n",
    "... some semi-advanced Code to manage BigQuery Tables including partitions. Though these sample files are so small partitions are not really needed this might come in handy at another time.\n",
    "\n",
    "\n",
    "\n",
    "### GCP Locations\n",
    "https://cloud.google.com/about/locations\n",
    "\n",
    "https://cloud.google.com/bigquery/docs/locations#supported_locations\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "by Markus Lauber (https://medium.com/@mlxl)\n",
    "\n",
    "https://yam-united.telekom.com/profile/markus-lauber/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edHKvTkitiSN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1725457047397,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "edHKvTkitiSN",
    "outputId": "134776e8-3e78-4360-8c05-bb2c340ca9b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: google.colab.auth.authenticate_user() is not supported in Colab Enterprise.\n"
     ]
    }
   ],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "# project_id = 'de12345-user-prod-1'\n",
    "project_id = 'de123456-user-prd-1'\n",
    "dataset_id = 'xgb_classification_project'\n",
    "bucket_id = 'gs://mybucket/' # enter your path or load the data in another way\n",
    "\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "from pandas_gbq import to_gbq\n",
    "\n",
    "# Initialize the BigQuery client\n",
    "client = bigquery.Client(project=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rrxv0HN0VzpJ",
   "metadata": {
    "id": "rrxv0HN0VzpJ"
   },
   "source": [
    "### Rename Columns that have - (hyphen) in their name to _ (underscore)\n",
    "\n",
    "Standard big query tables do not seem to like special characters in column names. So best to remove hyphens or integers at the start of the column name (in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "L4ghLHDlV-nE",
   "metadata": {
    "id": "L4ghLHDlV-nE"
   },
   "outputs": [],
   "source": [
    "def rename_columns_underscore_and_number(project_id, dataset_id, table_re_name):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      project_id:\n",
    "      dataset_id:\n",
    "      table_re_name:\n",
    "    \"\"\"\n",
    "    # Initialize a client\n",
    "    client = bigquery.Client(project=project_id)\n",
    "\n",
    "    # Get the table schema\n",
    "    table_re_ref = client.dataset(dataset_id).table(table_re_name)\n",
    "    table_re = client.get_table(table_re_ref)\n",
    "\n",
    "    # Prepare SQL to rename columns with hyphens or starting with a number\n",
    "    queries = []\n",
    "    for field in table_re.schema:\n",
    "        new_name = field.name\n",
    "\n",
    "        # Replace hyphens with underscores\n",
    "        if '-' in field.name:\n",
    "            new_name = new_name.replace('-', '_')\n",
    "\n",
    "        # Check if the column name starts with a digit\n",
    "        if field.name[0].isdigit():\n",
    "            new_name = f\"v_{new_name}\"\n",
    "\n",
    "        # If a change is required, prepare the SQL statement\n",
    "        if new_name != field.name:\n",
    "            print(\"Old: \", field.name, \" | New: \", new_name)\n",
    "            sql = f\"ALTER TABLE `{project_id}.{dataset_id}.{table_re_name}` RENAME COLUMN `{field.name}` TO `{new_name}`;\"\n",
    "            queries.append(sql)\n",
    "\n",
    "    # Execute the queries\n",
    "    for query in queries:\n",
    "        client.query(query)\n",
    "\n",
    "    print(\"Column renaming completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nr8x92I-wGZ9",
   "metadata": {
    "id": "nr8x92I-wGZ9"
   },
   "source": [
    "The Bucket where the Parquet files are being stored\n",
    "\n",
    "gs://my-bucket/test_data/train.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_OK1pnrZwG6F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3345,
     "status": "ok",
     "timestamp": 1725442543596,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "_OK1pnrZwG6F",
    "outputId": "cf9af4dd-3ef3-4bda-f547-4eb0c5513c74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job finished.\n"
     ]
    }
   ],
   "source": [
    "# Define your table ID (which includes dataset)\n",
    "table_name = 'census_train'\n",
    "table_id = f\"{project_id}.{dataset_id}.{table_name}\"\n",
    "\n",
    "# Set up the configuration for the load job\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    source_format=bigquery.SourceFormat.PARQUET,\n",
    "    write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE  # This line replaces the data instead of appending\n",
    ")\n",
    "\n",
    "# URI of the Parquet file in Google Cloud Storage\n",
    "# the files can be found here: https://github.com/ml-score/knime_meets_python/tree/main/machine_learning/binary\n",
    "# https://archive.ics.uci.edu/ml/datasets/census+income\n",
    "uri = bucket_id +  'test_data/train.parquet'\n",
    "\n",
    "# API request - starts the load job\n",
    "load_job = client.load_table_from_uri(\n",
    "    uri,\n",
    "    table_id,\n",
    "    job_config=job_config\n",
    ")\n",
    "\n",
    "# Wait for the job to complete\n",
    "load_job.result()\n",
    "\n",
    "print(\"Job finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EYxe-CboV0fQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2368,
     "status": "ok",
     "timestamp": 1725442571529,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "EYxe-CboV0fQ",
    "outputId": "a6707d65-d4a2-4495-d6bd-2cba32237a01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old:  education-num  | New:  education_num\n",
      "Old:  marital-status  | New:  marital_status\n",
      "Old:  capital-gain  | New:  capital_gain\n",
      "Old:  capital-loss  | New:  capital_loss\n",
      "Old:  hours-per-week  | New:  hours_per_week\n",
      "Old:  native-country  | New:  native_country\n",
      "Column renaming completed.\n"
     ]
    }
   ],
   "source": [
    "# Example usage to remove unwanted characters in column names:\n",
    "rename_columns_underscore_and_number(project_id, dataset_id, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eLZWCgxeW4Sq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1725442579576,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "eLZWCgxeW4Sq",
    "outputId": "cf846f8c-0dc7-4b18-db88-f0ea990e9d2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column renaming completed.\n"
     ]
    }
   ],
   "source": [
    "# sometimes it seems on go is not enough to capture all of the instances. So just run this a second or third time\n",
    "rename_columns_underscore_and_number(project_id, dataset_id, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h1RQZN4PxeV8",
   "metadata": {
    "id": "h1RQZN4PxeV8"
   },
   "outputs": [],
   "source": [
    "# Fetch the table (object)\n",
    "table = client.get_table(table_id)  # Make sure to provide the full table ID here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gE5u9FghxUXS",
   "metadata": {
    "id": "gE5u9FghxUXS"
   },
   "source": [
    "```Python\n",
    "@bpd.remote_function(bpd.DataFrame, str, str)\n",
    "def add_constant_column(df, column_name, constant_value):\n",
    "    df[column_name] = constant_value\n",
    "    return df\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RRTPTa34cDMe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 349,
     "status": "ok",
     "timestamp": 1725442591321,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "RRTPTa34cDMe",
    "outputId": "30aebf15-c851-4505-b5a0-f204955558dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "google.cloud.bigquery.table.Table"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iuNYOmD2yYVE",
   "metadata": {
    "id": "iuNYOmD2yYVE"
   },
   "outputs": [],
   "source": [
    "# Extract the schema and format it into the desired Python code structure\n",
    "schema_code_snippets = []\n",
    "for field in table.schema:\n",
    "    description = field.description if field.description else ''\n",
    "    schema_line = f'bigquery.SchemaField(\"{field.name}\", \"{field.field_type}\", description=\"{description}\")'\n",
    "    schema_code_snippets.append(schema_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cCfayy6iybNz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 381,
     "status": "ok",
     "timestamp": 1725442598127,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "cCfayy6iybNz",
    "outputId": "2c631dcd-ad25-4d39-f545-8118b88c2fcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields:  age, workclass, fnlwgt, education, education_num, marital_status, occupation, relationship, race, sex, capital_gain, capital_loss, hours_per_week, native_country, Target, row_id\n"
     ]
    }
   ],
   "source": [
    "# Extract the field names and join them with commas\n",
    "field_names = \", \".join(field.name for field in table.schema)\n",
    "\n",
    "# Print the comma-separated field names\n",
    "print(\"Fields: \", field_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56QgqakfydiU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1725442602883,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "56QgqakfydiU",
    "outputId": "1ba9e2c5-7984-4354-8429-31beb2e5d678"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Define the table schema with various data types\n",
      "schema =  [\n",
      "    bigquery.SchemaField(\"age\", \"INTEGER\", description=\"\"),\n",
      "    bigquery.SchemaField(\"workclass\", \"STRING\", description=\"\"),\n",
      "    bigquery.SchemaField(\"fnlwgt\", \"INTEGER\", description=\"\"),\n",
      "    bigquery.SchemaField(\"education\", \"STRING\", description=\"\"),\n",
      "    bigquery.SchemaField(\"education_num\", \"INTEGER\", description=\"\"),\n",
      "    bigquery.SchemaField(\"marital_status\", \"STRING\", description=\"\"),\n",
      "    bigquery.SchemaField(\"occupation\", \"STRING\", description=\"\"),\n",
      "    bigquery.SchemaField(\"relationship\", \"STRING\", description=\"\"),\n",
      "    bigquery.SchemaField(\"race\", \"STRING\", description=\"\"),\n",
      "    bigquery.SchemaField(\"sex\", \"STRING\", description=\"\"),\n",
      "    bigquery.SchemaField(\"capital_gain\", \"INTEGER\", description=\"\"),\n",
      "    bigquery.SchemaField(\"capital_loss\", \"INTEGER\", description=\"\"),\n",
      "    bigquery.SchemaField(\"hours_per_week\", \"INTEGER\", description=\"\"),\n",
      "    bigquery.SchemaField(\"native_country\", \"STRING\", description=\"\"),\n",
      "    bigquery.SchemaField(\"Target\", \"STRING\", description=\"\"),\n",
      "    bigquery.SchemaField(\"row_id\", \"STRING\", description=\"\")\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Combine the snippets into the full schema definition\n",
    "schema_code = \"[\\n    \" + \",\\n    \".join(schema_code_snippets) + \"\\n]\"\n",
    "\n",
    "# Print the generated code\n",
    "print(\"# Define the table schema with various data types\")\n",
    "print(\"schema = \", schema_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7tlL-jiz0gHN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1725442628813,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "7tlL-jiz0gHN",
    "outputId": "6762eceb-5b2b-48f6-f027-d28d95af0583"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table(TableReference(DatasetReference('de123456-user-prd-1', 'xgb_classification_project'), 'census_income'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define your dataset and table ID\n",
    "table_id = 'census_income'\n",
    "\n",
    "# TIMESTAMP,\n",
    "\n",
    "# bigquery.SchemaField(\"category\", \"STRING\", description=\"\")\n",
    "\n",
    "# Define the table schema with various data types\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"age\", \"INTEGER\", description=\"\"),\n",
    "    bigquery.SchemaField(\"workclass\", \"STRING\", description=\"\"),\n",
    "    bigquery.SchemaField(\"fnlwgt\", \"INTEGER\", description=\"\"),\n",
    "    bigquery.SchemaField(\"education\", \"STRING\", description=\"\"),\n",
    "    bigquery.SchemaField(\"education_num\", \"INTEGER\", description=\"\"),\n",
    "    bigquery.SchemaField(\"marital_status\", \"STRING\", description=\"\"),\n",
    "    bigquery.SchemaField(\"occupation\", \"STRING\", description=\"\"),\n",
    "    bigquery.SchemaField(\"relationship\", \"STRING\", description=\"\"),\n",
    "    bigquery.SchemaField(\"race\", \"STRING\", description=\"\"),\n",
    "    bigquery.SchemaField(\"sex\", \"STRING\", description=\"\"),\n",
    "    bigquery.SchemaField(\"capital_gain\", \"INTEGER\", description=\"\"),\n",
    "    bigquery.SchemaField(\"capital_loss\", \"INTEGER\", description=\"\"),\n",
    "    bigquery.SchemaField(\"hours_per_week\", \"INTEGER\", description=\"\"),\n",
    "    bigquery.SchemaField(\"native_country\", \"STRING\", description=\"\"),\n",
    "    bigquery.SchemaField(\"Target\", \"STRING\", description=\"\"),\n",
    "    bigquery.SchemaField(\"row_id\", \"STRING\", description=\"\"),\n",
    "    bigquery.SchemaField(\"category\", \"STRING\", description=\"Indicating if Test or Training\")\n",
    "]\n",
    "\n",
    "# Define integer range partitioning settings for the \"education_num\" column, could also be year or any other\n",
    "range_partitioning = bigquery.RangePartitioning(\n",
    "    field=\"education_num\",\n",
    "    range_=bigquery.PartitionRange(\n",
    "        start=1,\n",
    "        end=100,\n",
    "        interval=1\n",
    "    )\n",
    ")\n",
    "\n",
    "# Define table reference\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "\n",
    "# Define table with schema and partitioning settings\n",
    "table = bigquery.Table(table_ref, schema=schema)\n",
    "table.range_partitioning = range_partitioning\n",
    "\n",
    "# Specify clustering fields directly in the table object\n",
    "table.clustering_fields = [\"workclass\", \"occupation\"]\n",
    "\n",
    "# Create the table\n",
    "client.create_table(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CdyVnkHgX6j7",
   "metadata": {
    "id": "CdyVnkHgX6j7"
   },
   "source": [
    "### Import the TEST data also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1473E4_XX5d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3846,
     "status": "ok",
     "timestamp": 1725442642648,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "1473E4_XX5d6",
    "outputId": "e49d741a-ddb2-48d8-a9b1-1f85954fd22a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job finished.\n"
     ]
    }
   ],
   "source": [
    "# Define your table ID (which includes dataset)\n",
    "table_name = 'census_test'\n",
    "table_id = f\"{project_id}.{dataset_id}.{table_name}\"\n",
    "# table_id = '{}.{}.census_train'.format(project_id, dataset_name)\n",
    "\n",
    "# Set up the configuration for the load job\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    source_format=bigquery.SourceFormat.PARQUET,\n",
    "    write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE  # This line replaces the data instead of appending\n",
    ")\n",
    "\n",
    "# URI of the Parquet file in Google Cloud Storage\n",
    "# the files can be found here: https://github.com/ml-score/knime_meets_python/tree/main/machine_learning/binary\n",
    "# https://archive.ics.uci.edu/ml/datasets/census+income\n",
    "uri = bucket_id +  'test_data/test.parquet'\n",
    "\n",
    "# API request - starts the load job\n",
    "load_job = client.load_table_from_uri(\n",
    "    uri,\n",
    "    table_id,\n",
    "    job_config=job_config\n",
    ")\n",
    "\n",
    "# Wait for the job to complete\n",
    "load_job.result()\n",
    "\n",
    "print(\"Job finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SJMOjKaqWtgY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1915,
     "status": "ok",
     "timestamp": 1725442649470,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "SJMOjKaqWtgY",
    "outputId": "585d3f64-3d96-4425-df19-42a6d5454f72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old:  education-num  | New:  education_num\n",
      "Old:  marital-status  | New:  marital_status\n",
      "Old:  capital-gain  | New:  capital_gain\n",
      "Old:  capital-loss  | New:  capital_loss\n",
      "Old:  hours-per-week  | New:  hours_per_week\n",
      "Old:  native-country  | New:  native_country\n",
      "Column renaming completed.\n"
     ]
    }
   ],
   "source": [
    "rename_columns_underscore_and_number(project_id, dataset_id, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_VI7eDkkXYTG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1725442657995,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "_VI7eDkkXYTG",
    "outputId": "b0eb9db1-a337-478d-b0c5-6ee94c3d9886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column renaming completed.\n"
     ]
    }
   ],
   "source": [
    "rename_columns_underscore_and_number(project_id, dataset_id, table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sTWGDLeEXoJD",
   "metadata": {
    "id": "sTWGDLeEXoJD"
   },
   "source": [
    "## Insert TRAIN and TEST into the (partitioned) target table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "G4ZOiAZkaGpX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1725442669684,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "G4ZOiAZkaGpX",
    "outputId": "60369e30-b791-4a81-891e-fe7593c26fb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:  de123456-user-prd-1.xgb_classification_project.census_test  | Target table:  de123456-user-prd-1.xgb_classification_project.census_income\n"
     ]
    }
   ],
   "source": [
    "# Define your source and destination tables\n",
    "source_table = 'census_test'\n",
    "source_table_id = f\"{project_id}.{dataset_id}.{source_table}\"\n",
    "\n",
    "destination_table = 'census_income'\n",
    "destination_table_id = f\"{project_id}.{dataset_id}.{destination_table}\"\n",
    "\n",
    "print(\"Source: \", source_table_id, \" | Target table: \", destination_table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mdNl8B0HaOMP",
   "metadata": {
    "id": "mdNl8B0HaOMP"
   },
   "source": [
    "## Make sure the table is empty (also handy if you have to set up the table again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pzRQu5mkZ4XE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1935,
     "status": "ok",
     "timestamp": 1725442682813,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "pzRQu5mkZ4XE",
    "outputId": "1b4b3ec3-695b-4172-a4ad-b7485139a1cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table de123456-user-prd-1.xgb_classification_project.census_income has been truncated.\n"
     ]
    }
   ],
   "source": [
    "# Create a query to truncate the table\n",
    "query = f\"TRUNCATE TABLE `{destination_table_id}`\"\n",
    "\n",
    "# Execute the query\n",
    "query_job = client.query(query)\n",
    "query_job.result()  # Wait for the job to complete\n",
    "\n",
    "print(f\"Table {destination_table_id} has been truncated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FUonodiWay0Q",
   "metadata": {
    "id": "FUonodiWay0Q"
   },
   "source": [
    "## INSERT TEST data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6biYWRXaXLL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2738,
     "status": "ok",
     "timestamp": 1725442694748,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "b6biYWRXaXLL",
    "outputId": "c975dd25-476a-4953-e9f6-2f267fadabe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been appended successfully.\n"
     ]
    }
   ],
   "source": [
    "# SQL query to append data from source to destination\n",
    "query = f\"\"\"\n",
    "INSERT INTO `{destination_table_id}`\n",
    "SELECT *\n",
    ", '{source_table}' AS category\n",
    "FROM `{source_table_id}`\n",
    "WHERE row_id  NOT IN (SELECT DISTINCT row_id FROM `{destination_table_id}` WHERE category = '{source_table}')\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "query_job = client.query(query)  # Make an API request.\n",
    "\n",
    "# Wait for the job to complete\n",
    "query_job.result()\n",
    "\n",
    "print(\"Data has been appended successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q5GrPEiMa-lu",
   "metadata": {
    "id": "Q5GrPEiMa-lu"
   },
   "source": [
    "## now insert TRAIN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "llwt0xyuY_-i",
   "metadata": {
    "id": "llwt0xyuY_-i"
   },
   "outputs": [],
   "source": [
    "# Define your source and destination tables\n",
    "source_table = 'census_train'\n",
    "source_table_id = f\"{project_id}.{dataset_id}.{source_table}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q8CmcmK6ZYY8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2904,
     "status": "ok",
     "timestamp": 1725442706747,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "Q8CmcmK6ZYY8",
    "outputId": "760e3dfd-f9c3-4478-f41c-69c08ddcebe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been appended successfully.\n"
     ]
    }
   ],
   "source": [
    "# SQL query to append data from source to destination\n",
    "query = f\"\"\"\n",
    "INSERT INTO `{destination_table_id}`\n",
    "SELECT *\n",
    ", '{source_table}' AS category\n",
    "FROM `{source_table_id}`\n",
    "WHERE row_id  NOT IN (SELECT DISTINCT row_id FROM `{destination_table_id}` WHERE category = '{source_table}')\n",
    "\"\"\"\n",
    "# Execute the query\n",
    "query_job = client.query(query)  # Make an API request.\n",
    "\n",
    "# Wait for the job to complete\n",
    "query_job.result()\n",
    "\n",
    "print(\"Data has been appended successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zCFO2OeSZU18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2050,
     "status": "ok",
     "timestamp": 1725442713201,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "zCFO2OeSZU18",
    "outputId": "34a3fd48-36e3-471c-f66b-9747bf6a9428"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       category Target  Anzahl\n",
      "0   census_test      0   11126\n",
      "1   census_test      1    3527\n",
      "2  census_train      0   26029\n",
      "3  census_train      1    8160\n"
     ]
    }
   ],
   "source": [
    "# SQL Query - modify the query to match your table and desired aggregation\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "  category,\n",
    "  Target,\n",
    "  COUNT(*) AS Anzahl\n",
    "FROM\n",
    "  `{destination_table_id}` AS t1\n",
    "  GROUP BY category, Target\n",
    "  ORDER BY category, Target\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and load results into a DataFrame\n",
    "query_job = client.query(query)  # Run the query\n",
    "df = query_job.to_dataframe()  # Convert the results into a pandas DataFrame\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "GCP - 001 - Basic Big Query Operations",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
